{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import networkx as nx\n",
    "import json\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "def systematic_regular(no_of_samples, x, y):\n",
    "    # Calculate the dimensions of the regular grid\n",
    "    rows = int(np.sqrt(no_of_samples))\n",
    "    cols = int(np.ceil(no_of_samples / rows))\n",
    "\n",
    "    # Calculate the padding to ensure points are equally spaced\n",
    "    padding_x = (x - (rows - 1)) // rows\n",
    "    padding_y = (y - (cols - 1)) // cols\n",
    "\n",
    "    # Initialize points list\n",
    "    points = []\n",
    "\n",
    "    # Select equally spaced points with padding\n",
    "    for i in range(rows):\n",
    "        for j in range(cols):\n",
    "            points.append((int((i * (padding_x + 1)) + ((padding_x + 1)/2)), int((j * (padding_y + 1) + ((padding_y + 1)/2)))))\n",
    "\n",
    "    return points[:no_of_samples]\n",
    "\n",
    "def wageningen_w():\n",
    "    return [(25, 25), (25, 75), (25, 125), (25, 175), (63, 75), (88, 125), (138, 75), (113, 125), (175, 25), (175, 75), (175, 125), (175, 175)]\n",
    "    \n",
    "def retrieve_ids_per_sample_von_neumann(points, data, r):\n",
    "    samples =  [ [] for _ in range(len(points)) ]\n",
    "    for ind, row in data.iterrows():\n",
    "        for index, point in enumerate(points):\n",
    "            x1, y1 = point\n",
    "            x2 = row.x\n",
    "            y2 = row.y\n",
    "\n",
    "            if (abs(x1 - x2) + abs(y1 - y2)) <= r:\n",
    "                samples[index].append(ind)\n",
    "    return samples\n",
    "\n",
    "def pearson_cooccurrence(abundance_data, threshold=0):\n",
    "    # Initialize a graph\n",
    "    G = nx.Graph()\n",
    "    G.add_nodes_from(range(9))\n",
    "\n",
    "    # Calculate the Pearson correlation coefficient matrix\n",
    "    pearson_matrix = np.corrcoef(abundance_data, rowvar=False)\n",
    "    \n",
    "    pearson_matrix[np.isnan(pearson_matrix)] = 0\n",
    "\n",
    "    # Get the number of entities\n",
    "    num_entities = len(abundance_data[0])\n",
    "\n",
    "    # Iterate through the Pearson correlation matrix to create co-occurrence edges\n",
    "    for i in range(num_entities):\n",
    "        for j in range(i + 1, num_entities):\n",
    "            # Check if the correlation coefficient exceeds the threshold\n",
    "            if (pearson_matrix[i][j] > threshold):\n",
    "                G.add_edge(i, j, weight=pearson_matrix[i][j])\n",
    "\n",
    "    return G, pearson_matrix\n",
    "\n",
    "def manhattan_neighborhood_matrix(df):\n",
    "    # Initialize the grid dictionary\n",
    "    grid = {}\n",
    "    \n",
    "    # Populate the grid with entity locations and types\n",
    "    for idx, row in df.iterrows():\n",
    "        t, x, y, z = row['type'], row['x'], row['y'], row['z']\n",
    "        grid[(x, y, z)] = t\n",
    "    \n",
    "    # Define Manhattan neighbors offsets (distance 1 in 3D)\n",
    "    neighbors_offsets = [\n",
    "        (dx, dy, dz) \n",
    "        for dx in (-1, 0, 1) \n",
    "        for dy in (-1, 0, 1) \n",
    "        for dz in (-1, 0, 1)\n",
    "        if dx != 0 or dy != 0 or dz != 0\n",
    "    ]\n",
    "    \n",
    "    # Initialize the 9x9 matrix\n",
    "    matrix = np.zeros((9, 9), dtype=int)\n",
    "    \n",
    "    # Calculate type counts in the neighborhood\n",
    "    for (x, y, z), t in grid.items():\n",
    "        for dx, dy, dz in neighbors_offsets:\n",
    "            neighbor_pos = (x + dx, y + dy, z + dz)\n",
    "            if neighbor_pos in grid:\n",
    "                neighbor_type = grid[neighbor_pos]\n",
    "                matrix[int(t)][int(neighbor_type)] += 1\n",
    "    \n",
    "    return matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "filenames = ['agent_log_0', 'agent_log_1','agent_log_2','agent_log_3', 'agent_log_4', 'agent_log_5', 'agent_log_6', 'agent_log_7', 'agent_log_8', 'agent_log_9', 'agent_log_10', 'agent_log_11', 'agent_log_12', 'agent_log_13', 'agent_log_14', 'agent_log_15', 'agent_log_16', 'agent_log_17', 'agent_log_18', 'agent_log_19', 'agent_log_20']\n",
    "rs = [1, 3, 5, 7]\n",
    "inits = [0, 1, 2, 3, 4, 5, 6, 0, 1, 2, 3, 4, 5, 6, 0, 1, 2, 3, 4, 5, 6]\n",
    "\n",
    "#filenames = ['agent_log_20']\n",
    "#rs = [3]\n",
    "#inits = [6]\n",
    "\n",
    "x_max = 200\n",
    "y_max = 200\n",
    "z_max = 25\n",
    "\n",
    "no_of_samples = 16\n",
    "\n",
    "selected_points_reg = systematic_regular(no_of_samples, x_max, y_max)\n",
    "selected_points_w = wageningen_w()\n",
    "\n",
    "Gs = []\n",
    "\n",
    "Gs.append(nx.node_link_graph(json.loads('{\"directed\": false, \"multigraph\": false, \"graph\": {}, \"nodes\": [{\"id\": 0}, {\"id\": 1}, {\"id\": 2}, {\"id\": 3}, {\"id\": 4}, {\"id\": 5}, {\"id\": 6}, {\"id\": 7}, {\"id\": 8}], \"links\": [{\"weight\": 0.5826312884833548, \"source\": 0, \"target\": 3}, {\"weight\": 0.6148356427539814, \"source\": 0, \"target\": 4}, {\"weight\": 0.7306576990838498, \"source\": 1, \"target\": 2}, {\"weight\": 0.9003900420385831, \"source\": 1, \"target\": 5}, {\"weight\": -0.638579754693958, \"source\": 1, \"target\": 7}, {\"weight\": -0.27796656418881527, \"source\": 2, \"target\": 7}, {\"weight\": 0.46123412849139406, \"source\": 3, \"target\": 4}, {\"weight\": 0.6068144174853789, \"source\": 5, \"target\": 8}]}')))\n",
    "Gs.append(nx.node_link_graph(json.loads('{\"directed\": false, \"multigraph\": false, \"graph\": {}, \"nodes\": [{\"id\": 0}, {\"id\": 1}, {\"id\": 2}, {\"id\": 3}, {\"id\": 4}, {\"id\": 5}, {\"id\": 6}, {\"id\": 7}, {\"id\": 8}], \"links\": [{\"weight\": 0.5826312884833548, \"source\": 0, \"target\": 2}, {\"weight\": 0.6148356427539814, \"source\": 0, \"target\": 8}, {\"weight\": 0.7306576990838498, \"source\": 2, \"target\": 4}, {\"weight\": 0.9003900420385831, \"source\": 2, \"target\": 8}, {\"weight\": -0.638579754693958, \"source\": 3, \"target\": 6}, {\"weight\": -0.27796656418881527, \"source\": 3, \"target\": 8}, {\"weight\": 0.46123412849139406, \"source\": 4, \"target\": 5}, {\"weight\": 0.6068144174853789, \"source\": 7, \"target\": 8}]}')))\n",
    "Gs.append(nx.node_link_graph(json.loads('{\"directed\": false, \"multigraph\": false, \"graph\": {}, \"nodes\": [{\"id\": 0}, {\"id\": 1}, {\"id\": 2}, {\"id\": 3}, {\"id\": 4}, {\"id\": 5}, {\"id\": 6}, {\"id\": 7}, {\"id\": 8}], \"links\": [{\"weight\": 0.5826312884833548, \"source\": 1, \"target\": 4}, {\"weight\": 0.6148356427539814, \"source\": 1, \"target\": 5}, {\"weight\": 0.7306576990838498, \"source\": 1, \"target\": 6}, {\"weight\": 0.9003900420385831, \"source\": 2, \"target\": 5}, {\"weight\": -0.638579754693958, \"source\": 2, \"target\": 6}, {\"weight\": -0.27796656418881527, \"source\": 2, \"target\": 8}, {\"weight\": 0.46123412849139406, \"source\": 3, \"target\": 5}, {\"weight\": 0.6068144174853789, \"source\": 4, \"target\": 5}, {\"weight\": 0.5112680070896285, \"source\": 4, \"target\": 6}, {\"weight\": 0.42525572507758125, \"source\": 4, \"target\": 7}, {\"weight\": 0.4601658168250095, \"source\": 4, \"target\": 8}, {\"weight\": 0.4943223393958548, \"source\": 5, \"target\": 6}]}')))\n",
    "Gs.append(nx.node_link_graph(json.loads('{\"directed\": false, \"multigraph\": false, \"graph\": {}, \"nodes\": [{\"id\": 0}, {\"id\": 1}, {\"id\": 2}, {\"id\": 3}, {\"id\": 4}, {\"id\": 5}, {\"id\": 6}, {\"id\": 7}, {\"id\": 8}], \"links\": [{\"weight\": 0.5826312884833548, \"source\": 0, \"target\": 1}, {\"weight\": 0.6148356427539814, \"source\": 0, \"target\": 3}, {\"weight\": 0.7306576990838498, \"source\": 0, \"target\": 5}, {\"weight\": 0.9003900420385831, \"source\": 0, \"target\": 8}, {\"weight\": -0.638579754693958, \"source\": 1, \"target\": 3}, {\"weight\": -0.27796656418881527, \"source\": 1, \"target\": 5}, {\"weight\": 0.46123412849139406, \"source\": 1, \"target\": 6}, {\"weight\": 0.6068144174853789, \"source\": 3, \"target\": 7}, {\"weight\": 0.5112680070896285, \"source\": 3, \"target\": 8}, {\"weight\": 0.42525572507758125, \"source\": 4, \"target\": 5}, {\"weight\": 0.4601658168250095, \"source\": 4, \"target\": 6}, {\"weight\": 0.4943223393958548, \"source\": 4, \"target\": 7}, {\"weight\": -0.14671525430854027, \"source\": 4, \"target\": 8}]}')))\n",
    "Gs.append(nx.node_link_graph(json.loads('{\"directed\": false, \"multigraph\": false, \"graph\": {}, \"nodes\": [{\"id\": 0}, {\"id\": 1}, {\"id\": 2}, {\"id\": 3}, {\"id\": 4}, {\"id\": 5}, {\"id\": 6}, {\"id\": 7}, {\"id\": 8}], \"links\": [{\"weight\": 0.5826312884833548, \"source\": 0, \"target\": 1}, {\"weight\": 0.6148356427539814, \"source\": 0, \"target\": 3}, {\"weight\": 0.7306576990838498, \"source\": 0, \"target\": 4}, {\"weight\": 0.9003900420385831, \"source\": 0, \"target\": 6}, {\"weight\": -0.638579754693958, \"source\": 0, \"target\": 7}, {\"weight\": -0.27796656418881527, \"source\": 1, \"target\": 3}, {\"weight\": 0.46123412849139406, \"source\": 1, \"target\": 4}, {\"weight\": 0.6068144174853789, \"source\": 1, \"target\": 6}, {\"weight\": 0.5112680070896285, \"source\": 1, \"target\": 7}, {\"weight\": 0.42525572507758125, \"source\": 1, \"target\": 8}, {\"weight\": 0.4601658168250095, \"source\": 2, \"target\": 5}, {\"weight\": 0.4943223393958548, \"source\": 2, \"target\": 6}, {\"weight\": -0.14671525430854027, \"source\": 2, \"target\": 8}, {\"weight\": -0.4038872117981791, \"source\": 3, \"target\": 4}, {\"weight\": 0.5176903249517476, \"source\": 3, \"target\": 6}, {\"weight\": 0.7534244447856359, \"source\": 3, \"target\": 7}, {\"weight\": 0.5244768288592718, \"source\": 4, \"target\": 7}, {\"weight\": 0.7363358287149884, \"source\": 4, \"target\": 8}, {\"weight\": 0.631262017598583, \"source\": 5, \"target\": 6}, {\"weight\": 0.13566419265027413, \"source\": 5, \"target\": 8}, {\"weight\": 0.7444351489453024, \"source\": 6, \"target\": 7}, {\"weight\": -0.4320948133020824, \"source\": 7, \"target\": 8}]}')))\n",
    "Gs.append(nx.node_link_graph(json.loads('{\"directed\": false, \"multigraph\": false, \"graph\": {}, \"nodes\": [{\"id\": 0}, {\"id\": 1}, {\"id\": 2}, {\"id\": 3}, {\"id\": 4}, {\"id\": 5}, {\"id\": 6}, {\"id\": 7}, {\"id\": 8}], \"links\": [{\"weight\": 0.5826312884833548, \"source\": 0, \"target\": 1}, {\"weight\": 0.6148356427539814, \"source\": 0, \"target\": 3}, {\"weight\": 0.7306576990838498, \"source\": 0, \"target\": 4}, {\"weight\": 0.9003900420385831, \"source\": 0, \"target\": 6}, {\"weight\": -0.638579754693958, \"source\": 0, \"target\": 7}, {\"weight\": -0.27796656418881527, \"source\": 0, \"target\": 8}, {\"weight\": 0.46123412849139406, \"source\": 1, \"target\": 2}, {\"weight\": 0.6068144174853789, \"source\": 1, \"target\": 4}, {\"weight\": 0.5112680070896285, \"source\": 1, \"target\": 5}, {\"weight\": 0.42525572507758125, \"source\": 1, \"target\": 6}, {\"weight\": 0.4601658168250095, \"source\": 1, \"target\": 7}, {\"weight\": 0.4943223393958548, \"source\": 2, \"target\": 4}, {\"weight\": -0.14671525430854027, \"source\": 2, \"target\": 5}, {\"weight\": -0.4038872117981791, \"source\": 3, \"target\": 4}, {\"weight\": 0.5176903249517476, \"source\": 3, \"target\": 5}, {\"weight\": 0.7534244447856359, \"source\": 3, \"target\": 6}, {\"weight\": 0.5244768288592718, \"source\": 3, \"target\": 8}, {\"weight\": 0.7363358287149884, \"source\": 4, \"target\": 7}, {\"weight\": 0.631262017598583, \"source\": 4, \"target\": 8}, {\"weight\": 0.13566419265027413, \"source\": 5, \"target\": 7}, {\"weight\": 0.7444351489453024, \"source\": 5, \"target\": 8}, {\"weight\": -0.4320948133020824, \"source\": 6, \"target\": 8}, {\"weight\": -0.581091373256546, \"source\": 7, \"target\": 8}]}')))\n",
    "Gs.append(nx.node_link_graph(json.loads('{\"directed\": false, \"multigraph\": false, \"graph\": {}, \"nodes\": [{\"id\": 0}, {\"id\": 1}, {\"id\": 2}, {\"id\": 3}, {\"id\": 4}, {\"id\": 5}, {\"id\": 6}, {\"id\": 7}, {\"id\": 8}], \"links\": [{\"weight\": 0.5826312884833548, \"source\": 0, \"target\": 5}, {\"weight\": 0.6148356427539814, \"source\": 0, \"target\": 8}, {\"weight\": 0.7306576990838498, \"source\": 1, \"target\": 3}, {\"weight\": 0.9003900420385831, \"source\": 1, \"target\": 4}, {\"weight\": -0.638579754693958, \"source\": 1, \"target\": 6}, {\"weight\": -0.27796656418881527, \"source\": 2, \"target\": 4}, {\"weight\": 0.46123412849139406, \"source\": 2, \"target\": 7}, {\"weight\": 0.6068144174853789, \"source\": 2, \"target\": 8}, {\"weight\": 0.5112680070896285, \"source\": 3, \"target\": 4}, {\"weight\": 0.42525572507758125, \"source\": 3, \"target\": 6}, {\"weight\": 0.4601658168250095, \"source\": 3, \"target\": 7}, {\"weight\": 0.4943223393958548, \"source\": 3, \"target\": 8}, {\"weight\": -0.14671525430854027, \"source\": 4, \"target\": 5}, {\"weight\": -0.4038872117981791, \"source\": 4, \"target\": 6}, {\"weight\": 0.5176903249517476, \"source\": 5, \"target\": 7}, {\"weight\": 0.7534244447856359, \"source\": 5, \"target\": 8}]}')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "# File path where you want to write the lines\n",
    "file_path = \"analysis_results.txt\"\n",
    "\n",
    "for idx, filename in enumerate(filenames):\n",
    "    G = Gs[inits[idx]]\n",
    "    A = nx.adjacency_matrix(G).todense()\n",
    "    \n",
    "    df = pd.read_csv(\"../sosi/outputs/\" + filename + \".csv\")\n",
    "    data = df[df[\"tick\"] == 50]\n",
    "    data = data.reset_index(drop=True)\n",
    "    \n",
    "    for r in rs:\n",
    "        samples_w = retrieve_ids_per_sample_von_neumann(selected_points_w, data, r)\n",
    "        samples_reg = retrieve_ids_per_sample_von_neumann(selected_points_reg, data, r)\n",
    "    \n",
    "        sample_site_counts_w = []\n",
    "        for sample_site in samples_w:\n",
    "            df2 = data.iloc[sample_site]\n",
    "            count = df2['type'].value_counts().reindex(range(len(df[\"type\"].unique())), fill_value=0)\n",
    "            sample_site_counts_w.append([val for _, val in count.items()])\n",
    "    \n",
    "        sample_site_counts_reg = []\n",
    "        for sample_site in samples_reg:\n",
    "            df2 = data.iloc[sample_site]\n",
    "            count = df2['type'].value_counts().reindex(range(len(df[\"type\"].unique())), fill_value=0)\n",
    "            sample_site_counts_reg.append([val for _, val in count.items()])\n",
    "            \n",
    "        neighborhood_counts = manhattan_neighborhood_matrix(data)\n",
    "    \n",
    "        gt_pearson_net, gt_pearson = pearson_cooccurrence(neighborhood_counts, 0)\n",
    "        pearson_net_w, pearson_w = pearson_cooccurrence(sample_site_counts_w, 0)\n",
    "        pearson_net_reg, pearson_reg = pearson_cooccurrence(sample_site_counts_reg, 0)\n",
    "        \n",
    "        lines = []\n",
    "        \n",
    "        lines.append(filename + \" Diameter: \" + str(r))\n",
    "        lines.append(\"Initial co-occurrence <-> Ground truth\")\n",
    "        lines.append(\"MAE: \" + str(metrics.mean_absolute_error(A, gt_pearson)))\n",
    "        lines.append(\"MdAE: \" + str(metrics.median_absolute_error(A, gt_pearson)))\n",
    "        lines.append(\"R2: \" + str(metrics.r2_score(A, gt_pearson)))\n",
    "        lines.append(\"Ground truth <-> Wageningen W\")\n",
    "        lines.append(\"MAE: \" + str(metrics.mean_absolute_error(gt_pearson, pearson_w)))\n",
    "        lines.append(\"MdAE: \" + str(metrics.median_absolute_error(gt_pearson, pearson_w)))\n",
    "        lines.append(\"R2: \" + str(metrics.r2_score(gt_pearson, pearson_w)))\n",
    "        lines.append(\"Initial co-occurrence <-> Wageningen W\")\n",
    "        lines.append(\"MAE: \" + str(metrics.mean_absolute_error(A, pearson_w)))\n",
    "        lines.append(\"MdAE: \" + str(metrics.median_absolute_error(A, pearson_w)))\n",
    "        lines.append(\"R2: \" + str(metrics.r2_score(A, pearson_w)))\n",
    "        lines.append(\"Ground truth <-> Sys Reg\")\n",
    "        lines.append(\"MAE: \" + str(metrics.mean_absolute_error(gt_pearson, pearson_reg)))\n",
    "        lines.append(\"MdAE: \" + str(metrics.median_absolute_error(gt_pearson, pearson_reg)))\n",
    "        lines.append(\"R2: \" + str(metrics.r2_score(gt_pearson, pearson_reg)))\n",
    "        lines.append(\"Initial co-occurrence <-> Sys Reg\")\n",
    "        lines.append(\"MAE: \" + str(metrics.mean_absolute_error(A, pearson_reg)))\n",
    "        lines.append(\"MdAE: \" + str(metrics.median_absolute_error(A, pearson_reg)))\n",
    "        lines.append(\"R2: \" + str(metrics.r2_score(A, pearson_reg)) + \"\\n\")\n",
    "        \n",
    "        # Open the file in write mode\n",
    "        with open(file_path, \"w\") as file:\n",
    "            # Write each line to the file\n",
    "            for line in lines:\n",
    "                file.write(line + \"\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
